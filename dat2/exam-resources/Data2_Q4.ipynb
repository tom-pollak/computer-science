{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "## (i)\n",
    "\n",
    "Map reduce is a way to process data in paraell on a large, distributed dataset\n",
    "\n",
    "For example, there is a large text file and you must count the occurences of certain words in the text. You can do this by counting the occurences on each line then combining these totals together for the final count\n",
    "\n",
    "1. Split data of the text file into chunks, in this example I am using each line as an individual chunck\n",
    "2. Map each chunk to the number of occurences of each specified words in the line:\n",
    "    1. First the chunk is filtered, such that only relavent words are left\n",
    "    2. Then the occurences of the relevant words are counted. This is stored as a Counter object\n",
    "3. Reduce the multiple Counter objects into a total count by combining pairs of Counter objects together until only 1 object is left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'dog': 6, 'horse': 2, 'cat': 2, 'puppy': 2})\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from collections import Counter\n",
    "\n",
    "counted_words = [\"dog\", \"cat\", \"horse\", \"puppy\"]\n",
    "\n",
    "text = \"\"\"fsdkljfsdl dog sajf dfjksd horse dog\n",
    "fsd fsd cat fjsdks dog fsd dog\n",
    "dog dog horse dsfsd dfs\n",
    "fsdjfklf puppy cat fds fdsf\n",
    "puppy\"\"\"\n",
    "\n",
    "\n",
    "def filter_counted_words(word):\n",
    "    if word in counted_words:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def mapper(line):\n",
    "    words = line.split(\" \")\n",
    "    filtered_words = filter(filter_counted_words, words) # Unessecary words are filtered from the line\n",
    "    return Counter(filtered_words)\n",
    "\n",
    "\n",
    "def reducer(cnt1, cnt2):\n",
    "    cnt1.update(cnt2)\n",
    "    return cnt1\n",
    "\n",
    "chunks = text.split(\"\\n\") # Each chunk is just a line of the file\n",
    "mapped = map(mapper, chunks) # A Counter object is mapped to each chunk\n",
    "reduced = reduce(reducer, mapped) # Counter objects are reduced to a single object\n",
    "\n",
    "print(reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (ii)\n",
    "### (a)\n",
    "\n",
    "**mapper.py:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "csv = [line.split(\",\") for line in sys.stdin.read().splitlines()]\n",
    "df = pd.DataFrame(\n",
    "    csv, columns=[\"salesperson\", \"capp_size\", \"tea_size\", \"capp_price\", \"tea_price\"]\n",
    ")\n",
    "cap_df = df[[\"capp_size\", \"capp_price\"]].set_index(\"capp_size\")\n",
    "tea_df = df[[\"tea_size\", \"tea_price\"]].set_index(\"tea_size\")\n",
    "df = pd.concat([cap_df, tea_df]).fillna(0)\n",
    "df[\"\"] = df.capp_price.astype(float) + df.tea_price.astype(float)\n",
    "df.drop(columns=[\"capp_price\", \"tea_price\"], inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ```$ cat ../exam-resources/hot_drinks.csv | python3 mapper.py | sort```\n",
    "\n",
    "```\n",
    "capp_L   3.50\n",
    "capp_L   3.50\n",
    "capp_L   3.50\n",
    "capp_L   3.50\n",
    "capp_M   3.00\n",
    "capp_M   3.00\n",
    "capp_M   3.00\n",
    "capp_S   2.50\n",
    "capp_S   2.50\n",
    "capp_S   2.50\n",
    "capp_S   2.50\n",
    "capp_XL  4.50\n",
    "capp_XL  4.50\n",
    "capp_XL  4.50\n",
    "tea_L    2.75\n",
    "tea_L    2.75\n",
    "tea_L    2.75\n",
    "tea_L    2.75\n",
    "tea_M    2.00\n",
    "tea_M    2.00\n",
    "tea_M    2.00\n",
    "tea_S    1.50\n",
    "tea_S    1.50\n",
    "tea_S    1.50\n",
    "tea_S    1.50\n",
    "tea_S    1.50\n",
    "tea_XL   3.25\n",
    "tea_XL   3.25\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\n",
    "\n",
    "**reducer.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "csv = [line.split(\",\")[0].split() for line in sys.stdin.read().splitlines()][1:]\n",
    "df = pd.DataFrame(csv, columns=[\"type_size\", \"price\"]).set_index(\"type_size\")\n",
    "df.price = pd.to_numeric(df.price)\n",
    "\n",
    "\n",
    "df = df.groupby(level=0).sum()\n",
    "df.rename(columns={\"price\": \"\"}, inplace=True)\n",
    "df.index.name = None\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ```$ cat ../exam-resources/hot_drinks.csv | python3 mapper.py | sort | python3 reducer.py```\n",
    "\n",
    "```\n",
    "capp_L   14.0\n",
    "capp_M    9.0\n",
    "capp_S   10.0\n",
    "capp_XL  13.5\n",
    "tea_L    11.0\n",
    "tea_M     6.0\n",
    "tea_S     7.5\n",
    "tea_XL    6.5\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
